import os
import time
import random
import subprocess
import gc
import torch
import soundfile as sf
import numpy as np
import threading
import queue
import asyncio
from transformers import MusicgenForConditionalGeneration, MusicgenProcessor
from diffusers import StableDiffusionPipeline
import edge_tts

# =========================
# CONFIG
# =========================
# –£–±–µ–¥–∏—Å—å, —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∞ –≤ RunPod, –∏–ª–∏ –≤—Å—Ç–∞–≤—å –∫–ª—é—á —Å—é–¥–∞
STREAM_KEY = os.environ.get("TWITCH_STREAM_KEY") 
if not STREAM_KEY:
    print("‚ö†Ô∏è WARNING: TWITCH_STREAM_KEY not found. Stream will fail.")
    # STREAM_KEY = "live_xxxx_....." # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –∏ –≤—Å—Ç–∞–≤—å, –µ—Å–ª–∏ –ª–µ–Ω—å —á–µ—Ä–µ–∑ env

RTMP_URL = f"rtmp://live.twitch.tv/app/{STREAM_KEY}"
WORKDIR = "/workspace/airadio/data"
os.makedirs(WORKDIR, exist_ok=True)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"‚öôÔ∏è Device: {DEVICE} (RTX A4000 Power!)")

# –û—á–µ—Ä–µ–¥—å –¥–ª—è –≥–æ—Ç–æ–≤—ã—Ö –≤–∏–¥–µ–æ-—Å–µ–≥–º–µ–Ω—Ç–æ–≤
video_queue = queue.Queue(maxsize=5)

# =========================
# LOAD MODELS
# =========================
print("‚è≥ Loading MusicGen Medium (High Quality)...")
# –ò—Å–ø–æ–ª—å–∑—É–µ–º MEDIUM –º–æ–¥–µ–ª—å, —Ç–∞–∫ –∫–∞–∫ A4000 —ç—Ç–æ —Ç—è–Ω–µ—Ç –ª–µ–≥–∫–æ
processor = MusicgenProcessor.from_pretrained("facebook/musicgen-medium")
music_model = MusicgenForConditionalGeneration.from_pretrained(
    "facebook/musicgen-medium",
    torch_dtype=torch.float16 # FP16 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
).to(DEVICE)
music_model.eval()

print("‚è≥ Loading Stable Diffusion...")
sd_pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
).to(DEVICE)
sd_pipe.safety_checker = None

# =========================
# THE "BRAIN" (Smart DJ Logic)
# =========================
class DJBrain:
    def __init__(self):
        self.locations = ["Cyber-Tokyo", "Neo-Seoul", "Mars Colony 4", "Digital Void", "Sector 7"]
        self.weather = ["Acid Rain", "Neon Fog", "Solar Flares", "Data Storms", "Clear Skies"]
        self.topics = [
            "AI Rights", "The simulation theory", "Why humans love coffee", 
            "The update to Neural Link v5.0", "Old school internet archives"
        ]
    
    def get_script(self):
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π API –∫ GPT-4/Claude (CrewAI)
        # –ü–æ–∫–∞ –∏–º–∏—Ç–∏—Ä—É–µ–º —É–º–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        mode = random.choice(["weather", "news", "vibe"])
        
        if mode == "weather":
            loc = random.choice(self.locations)
            weath = random.choice(self.weather)
            return f"Current status in {loc}: {weath}. Stay safe, net-runners. Here is the next track."
        
        elif mode == "news":
            topic = random.choice(self.topics)
            return f"Trending now on the neural net: {topic}. Think about it while you listen to this beat."
        
        else:
            return "System optimal. Vitals stable. Injecting dopamine through audio waves. Enjoy."

    def get_music_prompt(self):
        genres = [
            "lo-fi hip hop, vinyl crackle, chill", 
            "synthwave, retrowave, 80s drums, driving", 
            "cyberpunk, industrial, dark bass, cinematic", 
            "deep house, melodic, vocal chops, summer", 
            "ambient, space drone, meditation, relaxing"
        ]
        return random.choice(genres)

brain = DJBrain()

# =========================
# HELPERS
# =========================
def cleanup():
    gc.collect()
    torch.cuda.empty_cache()

def save_audio_normalized(audio_tensor, filename, sr):
    """
    –í–ê–ñ–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ 16-bit PCM.
    –≠—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É '—à—É–º–∞' –≤–º–µ—Å—Ç–æ –∑–≤—É–∫–∞.
    """
    audio_np = audio_tensor[0, 0].cpu().float().numpy()
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –∫–ª–∏–ø–ø–∏–Ω–≥–∞)
    max_val = np.max(np.abs(audio_np))
    if max_val > 0:
        audio_np = audio_np / max_val * 0.9  # 90% –≥—Ä–æ–º–∫–æ—Å—Ç–∏
    
    sf.write(filename, audio_np, sr, subtype='PCM_16')

# =========================
# GENERATION WORKER
# =========================
def generate_segment(idx):
    print(f"\nüî® [Worker] Processing segment {idx}...")
    t0 = time.time()
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞–Ω–∏–µ –æ—Ç "–ú–æ–∑–≥–∞"
    music_prompt = brain.get_music_prompt()
    dj_text = brain.get_script()
    
    # –ü—É—Ç–∏
    music_path = os.path.join(WORKDIR, f"temp_music_{idx}.wav")
    voice_path = os.path.join(WORKDIR, f"temp_voice_{idx}.wav")
    cover_path = os.path.join(WORKDIR, f"temp_cover_{idx}.png")
    final_video = os.path.join(WORKDIR, f"segment_{idx}.ts") # .ts –ª—É—á—à–µ –∫–ª–µ–∏—Ç—Å—è

    # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º—É–∑—ã–∫–∏ (MusicGen)
    inputs = processor(text=[music_prompt], padding=True, return_tensors="pt").to(DEVICE)
    with torch.no_grad():
        # 1000 —Ç–æ–∫–µ–Ω–æ–≤ ~= 20 —Å–µ–∫—É–Ω–¥. Medium –º–æ–¥–µ–ª—å –¥–∞–µ—Ç —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ.
        audio_values = music_model.generate(**inputs, max_new_tokens=1000, guidance_scale=3.5)
    
    save_audio_normalized(audio_values, music_path, music_model.config.audio_encoder.sampling_rate)

    # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±–ª–æ–∂–∫–∏ (SD)
    with torch.no_grad():
        image = sd_pipe(f"{music_prompt}, masterpiece, 8k, digital art", num_inference_steps=20).images[0]
    image.save(cover_path)

    # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–∞ (TTS)
    asyncio.run(edge_tts.Communicate(dj_text, "en-US-ChristopherNeural").save(voice_path))

    # 5. –°–±–æ—Ä–∫–∞ –≤–∏–¥–µ–æ (FFmpeg)
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º—É–∑—ã–∫–∏ –¥–ª—è –ª—É–ø–∞
    f = sf.SoundFile(music_path)
    music_dur = len(f) / f.samplerate
    # –î–µ–ª–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç ~60 —Å–µ–∫—É–Ω–¥ (–ª—É–ø–∏–º –º—É–∑—ã–∫—É 3 —Ä–∞–∑–∞)
    total_dur = music_dur * 3 

    # –°–ª–æ–∂–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ FFmpeg:
    # - –õ—É–ø–∏–º –∫–∞—Ä—Ç–∏–Ω–∫—É
    # - –õ—É–ø–∏–º –º—É–∑—ã–∫—É
    # - –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ–º –≥–æ–ª–æ—Å –≤ –Ω–∞—á–∞–ª–µ
    # - –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∞—É–¥–∏–æ –ø—Ä–∏ –º–∏–∫—Å–µ
    # - –ö–æ–¥–∏—Ä—É–µ–º –∞—É–¥–∏–æ –≤ AAC —Å—Ä–∞–∑—É, —á—Ç–æ–±—ã —Å—Ç—Ä–∏–º–µ—Ä—É –±—ã–ª–æ –ª–µ–≥—á–µ
    cmd = [
        "ffmpeg", "-y", "-loglevel", "error",
        "-loop", "1", "-i", cover_path,              # 0: –ö–∞—Ä—Ç–∏–Ω–∫–∞
        "-i", voice_path,                            # 1: –ì–æ–ª–æ—Å
        "-stream_loop", "-1", "-i", music_path,      # 2: –ú—É–∑—ã–∫–∞ (–±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π –ª—É–ø, –æ–±—Ä–µ–∂–µ–º –ø–æ -t)
        "-t", str(total_dur),                        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞
        "-filter_complex",
        "[1:a]volume=1.5[v];[2:a]volume=0.7[m];[v][m]amix=inputs=2:duration=first:dropout_transition=3[a_mix];[a_mix]acompressor=ratio=4[a_out]",
        "-map", "0:v", "-map", "[a_out]",
        "-c:v", "libx264", "-preset", "fast", "-pix_fmt", "yuv420p", "-g", "60",
        "-c:a", "aac", "-b:a", "192k", "-ar", "44100",
        "-f", "mpegts", final_video
    ]
    
    subprocess.run(cmd, check=True)
    
    # –ß–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    for f in [music_path, voice_path, cover_path]:
        if os.path.exists(f): os.remove(f)
    
    cleanup()
    print(f"‚úÖ [Worker] Segment {idx} ready ({round(time.time()-t0)}s)")
    return final_video

# =========================
# THREADS
# =========================
def worker_thread():
    """–ü–æ—Å—Ç–æ—è–Ω–Ω–æ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ —Ñ–æ–Ω"""
    idx = 0
    while True:
        if video_queue.full():
            time.sleep(1)
            continue
        
        try:
            seg_path = generate_segment(idx)
            video_queue.put(seg_path)
            idx += 1
        except Exception as e:
            print(f"‚ùå Worker Error: {e}")
            time.sleep(5)

def streamer_thread():
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≥–æ—Ç–æ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ Twitch"""
    print("üì° Streamer started. Waiting for buffer...")
    
    # –ñ–¥–µ–º –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –±—É—Ñ–µ—Ä–∞ (–º–∏–Ω–∏–º—É–º 2 –≤–∏–¥–µ–æ)
    while video_queue.qsize() < 2:
        time.sleep(2)
        print(f"   Buffering: {video_queue.qsize()}/2...")

    print("üî¥ GOING LIVE!")

    # –ó–∞–ø—É—Å–∫–∞–µ–º FFmpeg –≤ —Ä–µ–∂–∏–º–µ —á—Ç–µ–Ω–∏—è –∏–∑ pipe
    stream_cmd = [
        "ffmpeg", "-re", 
        "-f", "concat", "-safe", "0", "-i", "pipe:0",
        "-c", "copy", # –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º, —Ç–∞–∫ –∫–∞–∫ Worker —É–∂–µ –≤—Å—ë –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–ª
        "-f", "flv", RTMP_URL
    ]
    
    process = subprocess.Popen(stream_cmd, stdin=subprocess.PIPE)

    while True:
        seg_path = video_queue.get()
        print(f"‚ñ∂Ô∏è Playing: {seg_path} (Queue: {video_queue.qsize()})")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è concat –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ FFmpeg
        # file '/path/to/file.ts'
        line = f"file '{seg_path}'\n".encode('utf-8')
        
        try:
            process.stdin.write(line)
            process.stdin.flush()
        except BrokenPipeError:
            print("‚ùå Stream pipe broken. Restarting...")
            break
            
        # –í–∞–∂–Ω–æ: –í —Ä–µ–∂–∏–º–µ concat —á–µ—Ä–µ–∑ pipe –º—ã –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ—Å—Ç–æ —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª —Å—Ä–∞–∑—É,
        # —Ç–∞–∫ –∫–∞–∫ ffmpeg –µ–≥–æ —á–∏—Ç–∞–µ—Ç.
        # –í –∏–¥–µ–∞–ª–µ –Ω—É–∂–Ω–æ —É–¥–∞–ª—è—Ç—å —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π. 
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –≤ —ç—Ç–æ–º —Å–∫—Ä–∏–ø—Ç–µ –º—ã –æ—Å—Ç–∞–≤–∏–º –∏—Ö –∫–æ–ø–∏—Ç—å—Å—è (–Ω–∞ A4000 –º–µ—Å—Ç–∞ –º–Ω–æ–≥–æ),
        # –ª–∏–±–æ –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å "–º—É—Å–æ—Ä—â–∏–∫" –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ.

# =========================
# MAIN
# =========================
if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º Worker –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    t_worker = threading.Thread(target=worker_thread, daemon=True)
    t_worker.start()

    # –°—Ç—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞–µ–º –≤ –≥–ª–∞–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ (–∏–ª–∏ —Ç–æ–∂–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º)
    streamer_thread()
