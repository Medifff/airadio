import os
import time
import random
import subprocess
import gc
import torch
import soundfile as sf
from transformers import MusicgenForConditionalGeneration, MusicgenProcessor
from diffusers import StableDiffusionPipeline
import edge_tts

# =========================
# ENV / CONFIG
# =========================
STREAM_KEY = os.environ.get("TWITCH_STREAM_KEY")
if not STREAM_KEY:
    raise RuntimeError("TWITCH_STREAM_KEY is not set")

RTMP_URL = f"rtmp://live.twitch.tv/app/{STREAM_KEY}"

WORKDIR = "/workspace/airadio/data"
os.makedirs(WORKDIR, exist_ok=True)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"‚öôÔ∏è Device: {DEVICE}")

# =========================
# LOAD MODELS
# =========================
print("‚è≥ Loading MusicGen...")
processor = MusicgenProcessor.from_pretrained("facebook/musicgen-small")
music_model = MusicgenForConditionalGeneration.from_pretrained(
    "facebook/musicgen-small",
    torch_dtype=torch.float32
).to(DEVICE)
music_model.eval()

print("‚è≥ Loading Stable Diffusion...")
sd = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
).to(DEVICE)
sd.safety_checker = None

# =========================
# PROMPTS
# =========================
MUSIC_PROMPTS = [
    "lo-fi hip hop beats, chill, rain",
    "cyberpunk synthwave, neon night",
    "ambient space drone, calm",
    "deep house, melodic, focus",
    "retrowave driving at night"
]

DJ_PHRASES = [
    "You are listening to AI Radio.",
    "Generated by code, enjoyed by humans.",
    "Relax and enjoy the vibe.",
    "Broadcasting live from the cloud.",
    "Infinite stream active."
]

# =========================
# HELPERS
# =========================
def cleanup():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        try:
            torch.cuda.ipc_collect()
        except Exception:
            pass

# =========================
# GENERATORS
# =========================
def gen_music(prompt, out_wav, retries=3):
    cleanup()
    inputs = processor(text=[prompt], return_tensors="pt").to(DEVICE)

    for attempt in range(retries):
        try:
            with torch.no_grad():
                audio = music_model.generate(
                    **inputs,
                    max_new_tokens=700,
                    do_sample=False
                )
            sr = music_model.config.audio_encoder.sampling_rate
            sf.write(out_wav, audio[0, 0].cpu().numpy(), sr)
            return
        except RuntimeError as e:
            print(f"‚ö†Ô∏è MusicGen failed ({attempt+1}/{retries}): {e}")
            cleanup()
            time.sleep(2)

    raise RuntimeError("MusicGen failed after retries")

def gen_cover(prompt, out_png):
    with torch.no_grad():
        img = sd(prompt, num_inference_steps=12).images[0]
    img.save(out_png)

async def gen_voice(text, out_wav):
    tts = edge_tts.Communicate(text, "en-US-ChristopherNeural")
    await tts.save(out_wav)

# =========================
# SEGMENT CREATION
# =========================
def make_segment(idx):
    print(f"\nüé∂ Generating segment {idx}")

    music_prompt = random.choice(MUSIC_PROMPTS)
    dj_text = random.choice(DJ_PHRASES)

    music_wav = f"{WORKDIR}/music_{idx}.wav"
    voice_wav = f"{WORKDIR}/voice_{idx}.wav"
    cover_png = f"{WORKDIR}/cover_{idx}.png"
    segment_mp4 = f"{WORKDIR}/segment_{idx}.mp4"

    gen_music(music_prompt, music_wav)
    gen_cover(f"{music_prompt}, digital art, cinematic, 4k", cover_png)

    import asyncio
    asyncio.run(gen_voice(dj_text, voice_wav))

    f = sf.SoundFile(music_wav)
    duration = (len(f) / f.samplerate) * 3 - 1

    cmd = [
        "ffmpeg", "-y", "-loglevel", "warning",
        "-loop", "1", "-i", cover_png,
        "-i", voice_wav,
        "-stream_loop", "2", "-i", music_wav,
        "-t", str(duration),
        "-filter_complex",
        "[1:a]volume=1.4[v];"
        "[2:a]volume=0.8[m];"
        "[v][m]amix=inputs=2:duration=longest[a];"
        "[0:v]scale=1280:720,format=yuv420p[vout]",
        "-map", "[vout]", "-map", "[a]",
        "-c:v", "libx264", "-preset", "veryfast",
        "-r", "30", "-g", "60",
        "-c:a", "aac", "-b:a", "160k",
        segment_mp4
    ]

    subprocess.run(cmd, check=True)

    for f in [music_wav, voice_wav, cover_png]:
        if os.path.exists(f):
            os.remove(f)

    cleanup()
    return segment_mp4

# =========================
# MAIN LOOP
# =========================
def run_radio():
    print("\nüöÄ Starting AI Radio")

    idx = 0
    buffer = []

    while True:
        while len(buffer) < 2:
            seg = make_segment(idx)
            buffer.append(seg)
            idx += 1

        seg = buffer.pop(0)
        print(f"üì° Streaming: {seg}")

        stream_cmd = [
            "ffmpeg", "-re", "-loglevel", "warning",
            "-i", seg,
            "-c:v", "copy",
            "-c:a", "aac", "-b:a", "160k", "-ar", "44100", "-ac", "2",
            "-f", "flv",
            "-rtmp_live", "live",
            "-flvflags", "no_duration_filesize",
            RTMP_URL
        ]

        subprocess.run(stream_cmd)

        if os.path.exists(seg):
            os.remove(seg)

        cleanup()

# =========================
# ENTRYPOINT
# =========================
if __name__ == "__main__":
    run_radio()
