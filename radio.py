import os
import time
import random
import subprocess
import gc
import soundfile as sf
import numpy as np
import threading
import queue
import asyncio
import torch
from transformers import MusicgenForConditionalGeneration, MusicgenProcessor
from diffusers import StableDiffusionPipeline
import edge_tts

# =========================
# 1. CONFIG & ENV
# =========================
# –ü–µ—Ä–µ–Ω–æ—Å–∏–º –∫—ç—à –Ω–∞ –±–æ–ª—å—à–æ–π –¥–∏—Å–∫
os.environ["HF_HOME"] = "/workspace/hf_cache"

STREAM_KEY = os.environ.get("TWITCH_STREAM_KEY")
if not STREAM_KEY:
    print("‚ö†Ô∏è WARNING: TWITCH_STREAM_KEY not found in env.")

RTMP_URL = f"rtmp://live.twitch.tv/app/{STREAM_KEY}"
WORKDIR = "/workspace/airadio/data"
os.makedirs(WORKDIR, exist_ok=True)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"‚öôÔ∏è Device: {DEVICE}")

# –û—á–µ—Ä–µ–¥—å —Å–µ–≥–º–µ–Ω—Ç–æ–≤
video_queue = queue.Queue(maxsize=4)

# =========================
# 2. LOAD MODELS (Optimized for A4000)
# =========================

def cleanup():
    gc.collect()
    torch.cuda.empty_cache()

print("‚è≥ Loading MusicGen Medium...")
# FIX: –ò—Å–ø–æ–ª—å–∑—É–µ–º float32, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å NaN/—à—É–º–∞ –ø—Ä–∏ guidance_scale
# –ù–∞ A4000 (16GB) –ø–∞–º—è—Ç–∏ —Ö–≤–∞—Ç–∏—Ç.
processor = MusicgenProcessor.from_pretrained("facebook/musicgen-medium")
music_model = MusicgenForConditionalGeneration.from_pretrained(
    "facebook/musicgen-medium",
    torch_dtype=torch.float32, 
    use_safetensors=True
).to(DEVICE)
music_model.eval()

print("‚è≥ Loading Stable Diffusion...")
# SD –æ—Å—Ç–∞–≤–ª—è–µ–º –≤ fp16, –µ–π —ç—Ç–æ –æ–∫
sd_pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    use_safetensors=True
).to(DEVICE)
sd_pipe.safety_checker = None

# =========================
# 3. DJ LOGIC
# =========================
class DJBrain:
    def __init__(self):
        self.locations = ["Cyber-Tokyo", "Neo-Seoul", "Mars Colony 4", "Sector 7"]
        self.weather = ["Acid Rain", "Neon Fog", "Solar Flares", "Data Storms"]
        self.topics = ["AI Consciousness", "The Simulation", "Retro Hardware", "Neural Link Updates"]
    
    def get_script(self):
        mode = random.choice(["weather", "news", "vibe"])
        if mode == "weather":
            return f"Weather alert for {random.choice(self.locations)}: {random.choice(self.weather)}. Stay inside and listen."
        elif mode == "news":
            return f"Topic of the day: {random.choice(self.topics)}. Processing..."
        else:
            return "System optimal. Audio injection active. Enjoy the stream."

    def get_music_prompt(self):
        genres = [
            "lo-fi hip hop, chill, vinyl crackle", 
            "synthwave, retrowave, driving, 80s", 
            "cyberpunk, dark industrial, bass", 
            "deep house, melodic, summer vibe", 
            "ambient, space drone, meditation"
        ]
        return random.choice(genres)

brain = DJBrain()

# =========================
# 4. AUDIO PROCESSING
# =========================
def save_audio_normalized(audio_tensor, filename, sr):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è + –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ PCM_16"""
    audio_np = audio_tensor[0, 0].cpu().float().numpy()
    max_val = np.max(np.abs(audio_np))
    if max_val > 0:
        audio_np = audio_np / max_val * 0.95
    sf.write(filename, audio_np, sr, subtype='PCM_16')

# =========================
# 5. WORKER (GENERATOR)
# =========================
def generate_segment(idx):
    print(f"\nüî® [Worker] Processing segment {idx}...")
    t0 = time.time()
    
    music_prompt = brain.get_music_prompt()
    dj_text = brain.get_script()
    
    # –§–∞–π–ª—ã
    music_path = os.path.join(WORKDIR, f"temp_music_{idx}.wav")
    voice_path = os.path.join(WORKDIR, f"temp_voice_{idx}.wav")
    cover_path = os.path.join(WORKDIR, f"temp_cover_{idx}.png")
    final_video = os.path.join(WORKDIR, f"segment_{idx}.ts")

    # A. MusicGen
    inputs = processor(text=[music_prompt], padding=True, return_tensors="pt").to(DEVICE)
    with torch.no_grad():
        # fp32 –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å guidance_scale
        audio_values = music_model.generate(**inputs, max_new_tokens=1000, guidance_scale=3.0)
    
    save_audio_normalized(audio_values, music_path, music_model.config.audio_encoder.sampling_rate)

    # B. Stable Diffusion
    with torch.no_grad():
        image = sd_pipe(f"{music_prompt}, masterpiece, 8k, wallpaper", num_inference_steps=20).images[0]
    image.save(cover_path)

    # C. TTS
    asyncio.run(edge_tts.Communicate(dj_text, "en-US-ChristopherNeural").save(voice_path))

    # D. FFmpeg Assembly
    f = sf.SoundFile(music_path)
    music_dur = len(f) / f.samplerate
    total_dur = music_dur * 3  # Loop 3 times (~60 sec)

    # FIX: duration=longest (—á—Ç–æ–±—ã –º—É–∑—ã–∫–∞ –Ω–µ –æ–±—Ä–µ–∑–∞–ª–∞—Å—å –ø–æ –≥–æ–ª–æ—Å—É)
    # FIX: acompressor (–≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å)
    cmd = [
        "ffmpeg", "-y", "-loglevel", "error",
        "-loop", "1", "-i", cover_path,
        "-i", voice_path,
        "-stream_loop", "-1", "-i", music_path,
        "-t", str(total_dur),
        "-filter_complex",
        "[1:a]volume=1.4[v];[2:a]volume=0.8[m];[v][m]amix=inputs=2:duration=longest:dropout_transition=2[mix];[mix]acompressor=ratio=4[aout]",
        "-map", "0:v", "-map", "[aout]",
        "-c:v", "libx264", "-preset", "fast", "-pix_fmt", "yuv420p", "-g", "60",
        "-c:a", "aac", "-b:a", "192k", "-ar", "44100",
        "-f", "mpegts", final_video
    ]
    
    subprocess.run(cmd, check=True)
    
    # Cleanup temps
    for f in [music_path, voice_path, cover_path]:
        if os.path.exists(f): os.remove(f)
    
    cleanup() # –ß–∏—Å—Ç–∏–º VRAM
    print(f"‚úÖ [Worker] Segment {idx} ready ({round(time.time()-t0)}s)")
    return final_video

def worker_thread():
    idx = 0
    while True:
        if video_queue.full():
            time.sleep(1)
            continue
        try:
            seg_path = generate_segment(idx)
            video_queue.put(seg_path)
            idx += 1
        except Exception as e:
            print(f"‚ùå Worker Error: {e}")
            time.sleep(5)

# =========================
# 6. STREAMER (Correct Implementation)
# =========================
def streamer_thread():
    print("üì° Streamer started. Buffering...")
    while video_queue.qsize() < 2:
        time.sleep(2)
    print("üî¥ GOING LIVE!")

    # FIX: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π pipe streaming (Byte Feeding)
    # –ú—ã –æ—Ç–∫—Ä—ã–≤–∞–µ–º FFmpeg –æ–¥–∏–Ω —Ä–∞–∑ –∏ –∫–æ—Ä–º–∏–º –µ–≥–æ –±–∞–π—Ç–∞–º–∏ .ts —Ñ–∞–π–ª–æ–≤
    stream_cmd = [
        "ffmpeg", "-re",
        "-f", "mpegts", "-i", "pipe:0", # –ß–∏—Ç–∞–µ–º mpegts –∏–∑ stdin
        "-c", "copy",                   # –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º, —Ç–∞–∫ –∫–∞–∫ Worker —É–∂–µ —Å–∂–∞–ª
        "-f", "flv", RTMP_URL
    ]
    
    process = subprocess.Popen(stream_cmd, stdin=subprocess.PIPE)

    while True:
        seg_path = video_queue.get()
        print(f"‚ñ∂Ô∏è Playing: {seg_path} (Queue: {video_queue.qsize()})")
        
        try:
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –∫—É—Å–∫–∞–º–∏ –∏ –ø–∏—à–µ–º –≤ pipe
            with open(seg_path, "rb") as f:
                while True:
                    chunk = f.read(4096 * 10) # –ß–∏—Ç–∞–µ–º –ø–æ ~40KB
                    if not chunk: break
                    process.stdin.write(chunk)
            
            # –í–∞–∂–Ω–æ: flush –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –∫–∞–∂–¥—ã–π —Ä–∞–∑, –Ω–æ –ø–æ–ª–µ–∑–µ–Ω
            process.stdin.flush()
            
        except BrokenPipeError:
            print("‚ùå Stream pipe broken. Restarting FFmpeg...")
            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞
            process = subprocess.Popen(stream_cmd, stdin=subprocess.PIPE)
        except Exception as e:
            print(f"‚ùå Streamer Error: {e}")

        # FIX: Garbage Collection (–ú—É—Å–æ—Ä—â–∏–∫)
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏—è
        if os.path.exists(seg_path):
            os.remove(seg_path)
            print(f"üóëÔ∏è Deleted {seg_path}")

# =========================
# MAIN
# =========================
if __name__ == "__main__":
    t_worker = threading.Thread(target=worker_thread, daemon=True)
    t_worker.start()
    streamer_thread()
